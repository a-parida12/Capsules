{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepCaps.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdjYDdENVt08",
        "colab_type": "text"
      },
      "source": [
        "# DeepCaps\n",
        "Deep Capsule networks based on [DeepCaps: Going Deeper with Capsule Networks](https://arxiv.org/pdf/1904.09546.pdf).\n",
        "Implementation based on the original [DeepCaps](https://github.com/brjathu/deepcaps) and [DeepCaps-PyTorch](https://github.com/HopefulRational/DeepCaps-PyTorch) implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZDGCuA-P6PF",
        "colab_type": "code",
        "outputId": "aceefe5b-9bd4-40bc-9130-827e77e94761",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from keras.utils import to_categorical\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import math\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KtH0UTJWjnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMJMI9KEXAyq",
        "colab_type": "text"
      },
      "source": [
        "### Helper Ftions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6a7hod-W_8n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squash(s, dim=-1):\n",
        "  eps=1e-8\n",
        "  norm = torch.norm(s, dim=dim, keepdim=True)\n",
        "  return (norm /(1 + norm**2 + eps)) * s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7HYzLOaXNrf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax3D(x, dim):\n",
        "  return (torch.exp(x) / torch.sum(torch.sum(torch.sum(torch.exp(x), dim=dim[0], keepdim=True), dim=dim[1], keepdim=True), dim=dim[2], keepdim=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkz0F7hHl2We",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(tensor, num_classes=10):\n",
        "    return torch.eye(num_classes).cuda().index_select(dim=0, index=tensor.cuda()) # One-hot encode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSsw-6xwXUPD",
        "colab_type": "text"
      },
      "source": [
        "### Layers\n",
        "\n",
        "Layer Modules required for DeepCaps network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkigQJnyXS1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvertToCaps(nn.Module):\n",
        "  def __init__(self):\n",
        "    '''\n",
        "    Convert ConvLayer Outputs into Capsules.\n",
        "    ConvLayer Out: NxCxHxW\n",
        "    Capsule Shape: NxNCxDxHxW\n",
        "    NC: Number of capsules.\n",
        "    D: Capsule Dimension.\n",
        "    '''\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x):\n",
        "    return x.unsqueeze(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9OxQxuHZDib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FlattenCaps(nn.Module):\n",
        "  def __init__(self):\n",
        "    '''\n",
        "    Transposes and Flattens capsules.\n",
        "    Input Shape: NxNCxDxHxW\n",
        "    Output Shape: Nx[NCxHxW]xD\n",
        "    '''\n",
        "    super().__init__()\n",
        "  def forward(self, x):\n",
        "    n, nc, d, h, w = x.shape\n",
        "    x = x.permute(0,3,4,1,2).contiguous()\n",
        "    return x.view(n,nc*h*w,d)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePsKgO7IZ6WG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsToScalars(nn.Module):\n",
        "  def __init__(self):\n",
        "    '''\n",
        "    Returns norm of capsule taken along the capsule dimension dim.\n",
        "    Norm/Length of capsules is the probablity that the \n",
        "    object detected by that capsule exists.\n",
        "    '''\n",
        "    super().__init__()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    return torch.norm(x,dim=2)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-NXCCJSakTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvCaps2D(nn.Module):\n",
        "  def __init__(self, nc_i, dim_i, nc_j, dim_j, kernel_size=3, stride=1,padding=1, r_num=1):\n",
        "    '''\n",
        "    2D Convolutional Capsule Layer. \n",
        "    Conv2DCaps is similar to a convolutional layer,\n",
        "    except that its outputs will be squashed 4D tensors.\n",
        "    i --> current layer.\n",
        "    j --> next layer.\n",
        "    Arguments\n",
        "    ---\n",
        "    `nc_i`: number of capsules in layer i.\n",
        "    `dim_i`: dimensions of capsules in layer i.\n",
        "    `nc_j`: number of capsules in layer j.\n",
        "    `dim_j`: dimensions of capsules in layer j.\n",
        "    `kernel_size`: Convolutional filter size.\n",
        "    `stride`: convolution stride.\n",
        "    `padding`: convolution padding.\n",
        "    `r_num`: number of routing iterations.\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.nc_i = nc_i\n",
        "    self.dim_i = dim_i\n",
        "    self.nc_j = nc_j\n",
        "    self.dim_j = dim_j\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding=padding\n",
        "    self.r_num=r_num\n",
        "\n",
        "    in_channels = self.nc_i * self.dim_i\n",
        "    out_channels = self.nc_j * self.dim_j\n",
        "\n",
        "    self.conv = nn.Conv2d(in_channels,out_channels,\n",
        "                          self.kernel_size,self.stride, self.padding)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # x.shape: NxNCxDxHxW\n",
        "    n, nc, dim, h, w = x.shape\n",
        "    # Reshape x from NxNCxDxHxW --> Nx[NCxD]XHXW\n",
        "    x = x.view(n,nc*dim, h, w)\n",
        "\n",
        "    x = self.conv(x)\n",
        "    h_j, w_j = x.shape[-2:]\n",
        "\n",
        "    #reshape back to NxNCxDxHxW\n",
        "    x = x.view(n,self.nc_j,self.dim_j,h_j,w_j)\n",
        "    \n",
        "    # Squash and return x.\n",
        "    return squash(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OuSQ26LfCvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvCaps3D(nn.Module):\n",
        "  def __init__(self, nc_i, dim_i, nc_j, dim_j,r_num=3, kernel_size=3, padding = (0,1,1)):\n",
        "    '''\n",
        "    3D Convolutional Capsule Layer.\n",
        "    ConvCaps3D uses 3D convolutions with Dynamic Routing\n",
        "    when num_routings is set greater than 1.\n",
        "    i --> current layer.\n",
        "    j --> next layer.\n",
        "    Arguments\n",
        "    ---\n",
        "    `nc_i`: number of capsules in layer i.\n",
        "    `dim_i`: dimensions of capsules in layer i.\n",
        "    `nc_j`: number of capsules in layer j.\n",
        "    `dim_j`: dimensions of capsules in layer j.\n",
        "    `kernel_size`: Convolutional filter size.\n",
        "    `stride`: convolution stride.\n",
        "    `padding`: convolution padding.\n",
        "    `r_num`: number of routing iterations.\n",
        "    '''\n",
        "    super().__init__()\n",
        "    self.nc_i = nc_i\n",
        "    self.dim_i = dim_i\n",
        "    self.nc_j = nc_j\n",
        "    self.dim_j = dim_j\n",
        "    self.kernel_size = kernel_size\n",
        "    self.r_num=r_num\n",
        "\n",
        "\n",
        "    self.stride = (dim_i,1,1)\n",
        "    self.padding= padding\n",
        "\n",
        "    in_channels = 1\n",
        "    out_channels = self.nc_j * self.dim_j\n",
        "\n",
        "    self.conv3d = nn.Conv3d(in_channels,out_channels,\n",
        "                            self.kernel_size,self.stride,self.padding)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    # x.shape = NxNCxDxHxW\n",
        "    n, nc, dim, h, w = x.shape\n",
        "\n",
        "    x = x.view(n,nc*dim, h, w)\n",
        "\n",
        "    x = x.unsqueeze(1)\n",
        "    x = self.conv3d(x)\n",
        "\n",
        "    h_j, w_j = x.shape[-2:]\n",
        "\n",
        "    x = x.view(n, self.nc_i, self.nc_j, self.dim_j ,h_j, w_j)\n",
        "\n",
        "    # Transpose to NxHxWxDjxNCjxNCi for routing updates.\n",
        "\n",
        "    x = x.permute(0,4,5,3,2,1)\n",
        "\n",
        "    # B matrix for routing coefficients.\n",
        "    # B.shape: NxHxWx1xNCjxNCi\n",
        "    self.B = x.new(x.shape[0],h_j,w_j,1,self.nc_j,self.nc_i).to(device)\n",
        "\n",
        "    x = self.update_routing(x, self.r_num)\n",
        "    \n",
        "    return x\n",
        "  \n",
        "  def update_routing(self, x, num_r=3):\n",
        "    #x.shape = NxHxWxDjxNCjxNCi\n",
        "    for ix in range(num_r):\n",
        "      k = softmax3D(self.B,(1,2,3))\n",
        "      s = (k * x).sum(dim=-1,keepdim=True)\n",
        "      s_hat  = squash(s)\n",
        "\n",
        "      if ix < num_r-1:\n",
        "        agreements = (s_hat * x).sum(dim=3, keepdim=True)\n",
        "        self.B = self.B = agreements\n",
        "\n",
        "    s_hat = s_hat.squeeze(-1)\n",
        "    batch, h_j, w_j, d_j, n_j  = s_hat.shape\n",
        "\n",
        "    return s_hat.reshape(batch,n_j,d_j,h_j,w_j)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAh3JHH9l9au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MaskCID(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  \n",
        "  def forward(self, x, target=None):\n",
        "    if target is None:\n",
        "      #Inference mode\n",
        "      classes = torch.norm(x,dim=2)\n",
        "      pred_class = classes.max(dim=1)[1].squeeze()\n",
        "    else:\n",
        "      pred_class = target.max(dim=1)[1]\n",
        "    \n",
        "    increasing = torch.arange(start=0, end = x.shape[0]).to(device)\n",
        "\n",
        "    m = torch.stack([increasing,pred_class], dim=1)\n",
        "\n",
        "    masked = torch.zeros((x.shape[0],1)+x.shape[2:])\n",
        "    # import pdb; pdb.set_trace()\n",
        "    for i in increasing:\n",
        "      masked[i] = x[m[i][0],m[i][1],:].unsqueeze(0)\n",
        "\n",
        "    return masked.squeeze(-1), pred_class"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmrCLkql_JOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseCaps_v1(nn.Module):\n",
        "  def __init__(self, nc=10, num_routes=640, in_dim=8, out_dim=16, routing_iters=3):\n",
        "      '''\n",
        "      Dense Capsule Layer.\n",
        "      '''\n",
        "      super().__init__()\n",
        "      self.nc = nc\n",
        "      self.num_routes = num_routes\n",
        "      self.r_it = routing_iters\n",
        "\n",
        "      self.W = nn.Parameter(torch.randn(1,num_routes, nc, out_dim, in_dim) * 0.01).to(device)\n",
        "      self.bias = nn.Parameter(torch.rand(1, 1, nc, out_dim) * 0.01)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.unsqueeze(2).unsqueeze(4)\n",
        "\n",
        "    u_hat = torch.matmul(self.W,x).squeeze()\n",
        "\n",
        "    b_ij = x.new(x.shape[0], self.num_routes, self.nc, 1).zero_()\n",
        "\n",
        "    for ix in range(self.r_it):\n",
        "      c_ij = F.softmax(b_ij, dim=2)\n",
        "      s_j = (c_ij * u_hat).sum(dim=-1, keepdim=True) + self.bias\n",
        "      v_j = squash(s_j, dim=-1)\n",
        "\n",
        "      if ix<self.r_it-1:\n",
        "        a_ij = (u_hat * v_j).sum(dim=-1, keepdim=True)\n",
        "        b_ij = b_ij + a_ij\n",
        "    v_j = v_j.squeeze()\n",
        "    return v_j"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU-l6SlDto-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseCaps_v2(nn.Module):\n",
        "  def __init__(self, nc=10, num_routes=640, in_dim=8, out_dim=16, routing_iters=3):\n",
        "      '''\n",
        "      Dense Capsule Layer.\n",
        "      '''\n",
        "      super().__init__()\n",
        "      self.nc = nc\n",
        "      self.num_routes = num_routes\n",
        "      self.out_dim=out_dim\n",
        "      self.r_it = routing_iters\n",
        "\n",
        "      self.W = nn.Parameter(torch.Tensor(num_routes, in_dim, nc * out_dim))\n",
        "      self.bias = nn.Parameter(torch.rand(1, 1, nc, out_dim) * 0.01)\n",
        "      self.b = nn.Parameter(torch.zeros(num_routes,nc))\n",
        "      self.reset_params()\n",
        "  def reset_params(self):\n",
        "    stdv = 1/math.sqrt(self.num_routes)\n",
        "    self.W.data.uniform_(-stdv, stdv)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.unsqueeze(2)#.unsqueeze(4)\n",
        "\n",
        "    u_hat = torch.matmul(x,self.W)\n",
        "    u_hat = u_hat.view(u_hat.size(0),self.num_routes, self.nc, self.out_dim)\n",
        "\n",
        "    c = F.softmax(self.b)\n",
        "    s = (c.unsqueeze(2) * u_hat).sum(dim=1)\n",
        "    v = squash(s)\n",
        "\n",
        "    if self.r_it > 0:\n",
        "      bBatch = self.b.expand((u_hat.shape[0],self.num_routes,self.nc))\n",
        "      for r in range(self.r_it):\n",
        "        v = v.unsqueeze(1)\n",
        "        bBatch = bBatch + (u_hat * v).sum(-1)\n",
        "\n",
        "        c = F.softmax(bBatch.view(-1,self.nc)).view(-1,self.num_routes,self.nc,1)\n",
        "        s = (c * u_hat).sum(dim=1)\n",
        "        v = squash(s)\n",
        "      \n",
        "    return v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM_8QRCe_BUH",
        "colab_type": "text"
      },
      "source": [
        "### Networks\n",
        "Networks that make up the DenseCaps Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfWYlpTC_ATR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, caps_dim=16, num_caps=1, img_size=28, out_channels=1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.num_caps = num_caps\n",
        "    self.out_channels=1\n",
        "    self.img_size=img_size\n",
        "\n",
        "    # self.dense = nn.Linear(caps_dim*num_caps, 7*7*16)\n",
        "    self.fc = nn.Linear(caps_dim*num_caps,7*7*16).to(device)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    self.reconst_layers1 = nn.Sequential(nn.BatchNorm2d(num_features=16, momentum=0.8),\n",
        "                                            nn.ConvTranspose2d(in_channels=16, out_channels=64, \n",
        "                                                               kernel_size=3, stride=1, padding=1)\n",
        "                                            )\n",
        "    self.reconst_layers2 = nn.ConvTranspose2d(in_channels=64, out_channels=32, \n",
        "                                                  kernel_size=3, stride=2, padding=1\n",
        "                                                 )\n",
        "    self.reconst_layers3 = nn.ConvTranspose2d(in_channels=32, out_channels=16, \n",
        "                                                  kernel_size=3, stride=2, padding=1\n",
        "                                                 )\n",
        "                                            \n",
        "    self.reconst_layers4 = nn.ConvTranspose2d(in_channels=16, out_channels=1, \n",
        "                                              kernel_size=3, stride=1, padding=1\n",
        "                                              )\n",
        "                                        \n",
        "    self.reconst_layers5 = nn.ReLU()\n",
        "\n",
        "  def forward(self, x):\n",
        "    \n",
        "    batch = x.shape[0]\n",
        "\n",
        "    x = x.float().to(device)\n",
        "\n",
        "    x = self.fc(x)\n",
        "    x=self.relu(x)\n",
        "    x = x.reshape(-1,16,7,7)\n",
        "\n",
        "    x = self.reconst_layers1(x)\n",
        "    x = self.reconst_layers2(x)\n",
        "\n",
        "    p2d = (1,0,1,0)\n",
        "    x = F.pad(x, p2d, 'constant')\n",
        "    x = self.reconst_layers3(x)\n",
        "\n",
        "    p2d = (1,0,1,0)\n",
        "    x=F.pad(x,p2d)\n",
        "    x = self.reconst_layers4(x)\n",
        "\n",
        "    x = self.reconst_layers5(x)\n",
        "    x = x.reshape(batch,1,self.img_size,self.img_size)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMzxvRDeLciC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepCaps(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv2d = nn.Conv2d(1,128,3,1,1)\n",
        "    self.bn = nn.BatchNorm2d(128,1e-8,momentum=0.99)\n",
        "    self.toCaps = ConvertToCaps()\n",
        "\n",
        "    #inSize 28\n",
        "    self.convcaps1_1 = ConvCaps2D(128,1,32,4,3,2,1,1) \n",
        "    self.convcaps1_2 = ConvCaps2D(32,4,32,4,3,1,1,1) #inSize 14\n",
        "    self.convcaps1_3 = ConvCaps2D(32,4,32,4,3,1,1,1)\n",
        "    self.convcaps1_4 = ConvCaps2D(32,4,32,4,3,1,1,1)\n",
        "\n",
        "    #inSize 14\n",
        "    self.convcaps2_1 = ConvCaps2D(32,4,32,8,3,2,1,1) \n",
        "    self.convcaps2_2 = ConvCaps2D(32,8,32,8,3,1,1,1) #inSize 7\n",
        "    self.convcaps2_3 = ConvCaps2D(32,8,32,8,3,1,1,1)\n",
        "    self.convcaps2_4 = ConvCaps2D(32,8,32,8,3,1,1,1)\n",
        "\n",
        "    #inSize 7\n",
        "    self.convcaps3_1 = ConvCaps2D(32,8,32,8,3,2,1,1) \n",
        "    self.convcaps3_2 = ConvCaps2D(32,8,32,8,3,1,1,1) #inSize 4\n",
        "    self.convcaps3_3 = ConvCaps2D(32,8,32,8,3,1,1,1)\n",
        "    self.convcaps3_4 = ConvCaps2D(32,8,32,8,3,1,1,1)\n",
        "\n",
        "    #inSize 4\n",
        "    self.convcaps4_1 = ConvCaps2D(32,8,32,8,3,2,1,1) \n",
        "    self.convcaps3d4 = ConvCaps3D(32,8,32,8,3,3) #inSize 2\n",
        "    self.convcaps4_3 = ConvCaps2D(32,8,32,8,3,1,1,1)\n",
        "    self.convcaps4_4 = ConvCaps2D(32,8,32,8,3,1,1,1)\n",
        "\n",
        "    self.flat_caps = FlattenCaps()\n",
        "    #numCaps for MNIST: 640\n",
        "    #self, nc=10, num_routes=640, in_dim=8, out_dim=16, routing_iters=3\n",
        "    self.digitCaps = DenseCaps_v2()\n",
        "    \n",
        "    self.reconNet = Decoder(16,1,28,1)\n",
        "\n",
        "    self.caps_score = CapsToScalars()\n",
        "    self.mask = MaskCID()\n",
        "\n",
        "    self.mse_loss = nn.MSELoss(reduction='none')\n",
        "\n",
        "  def forward(self, x, target=None):\n",
        "    x = self.conv2d(x)\n",
        "    x = self.bn(x)\n",
        "    x = self.toCaps(x)\n",
        "\n",
        "    # print(x.shape)\n",
        "\n",
        "    #Block 1\n",
        "    x =self.convcaps1_1(x)\n",
        "    x_skip = self.convcaps1_2(x)\n",
        "    x = self.convcaps1_3(x)\n",
        "    x = self.convcaps1_4(x)\n",
        "    x = x+x_skip\n",
        "\n",
        "    #Block 2\n",
        "    x =self.convcaps2_1(x)\n",
        "    x_skip = self.convcaps2_2(x)\n",
        "    x = self.convcaps2_3(x)\n",
        "    x = self.convcaps2_4(x)\n",
        "    x = x+x_skip\n",
        "\n",
        "    #Block 3\n",
        "    x =self.convcaps3_1(x)\n",
        "    x_skip = self.convcaps3_2(x)\n",
        "    x = self.convcaps3_3(x)\n",
        "    x = self.convcaps3_4(x)\n",
        "    x = x+x_skip\n",
        "    x1 = x\n",
        "\n",
        "    #Block 1\n",
        "    x =self.convcaps4_1(x)\n",
        "    x_skip = self.convcaps3d4(x)\n",
        "    x = self.convcaps3_3(x)\n",
        "    x = self.convcaps3_4(x)\n",
        "    x = x+x_skip\n",
        "    x2 = x\n",
        "\n",
        "    xa = self.flat_caps(x1) # 512 Capsules\n",
        "    xb = self.flat_caps(x2) # 128 Capsules\n",
        "\n",
        "    x = torch.cat([xa,xb],dim=-2)\n",
        "\n",
        "    class_caps = self.digitCaps(x)\n",
        "    x = self.caps_score(class_caps)\n",
        "    masked, indices = self.mask(class_caps, target)\n",
        "    decoded = self.reconNet(masked)\n",
        "\n",
        "    return class_caps, masked, decoded, indices\n",
        "\n",
        "  def margin_loss(self, x, labels, lamda, m_plus, m_minus):\n",
        "    v_c = torch.norm(x, dim=2, keepdim=True)\n",
        "    tmp1 = F.relu(m_plus - v_c).view(x.shape[0], -1) ** 2\n",
        "    tmp2 = F.relu(v_c - m_minus).view(x.shape[0], -1) ** 2\n",
        "    loss = labels*tmp1 + lamda*(1-labels)*tmp2\n",
        "    loss = loss.sum(dim=1)\n",
        "    return loss\n",
        "\n",
        "  def reconst_loss(self, recnstrcted, data):\n",
        "    loss = self.mse_loss(recnstrcted.view(recnstrcted.shape[0], -1), data.view(recnstrcted.shape[0], -1))\n",
        "    return 0.4 * loss.sum(dim=1)\n",
        "\n",
        "  def loss(self, x, recnstrcted, data, labels, lamda=0.5, m_plus=0.9, m_minus=0.1):\n",
        "    loss = self.margin_loss(x, labels, lamda, m_plus, m_minus) + self.reconst_loss(recnstrcted, data)\n",
        "    return loss.mean()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0t0wmFfqXGo9",
        "colab_type": "text"
      },
      "source": [
        "### Dataloader\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDum2OH9XGYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNISTData(Dataset):\n",
        "  def __init__(self,mode='train'):\n",
        "    super().__init__()\n",
        "    if 'test' in mode.lower():\n",
        "      fname = 'mnist_test.csv'\n",
        "    else:\n",
        "      fname = 'mnist_train_small.csv'\n",
        "      \n",
        "    dataset = pd.read_csv('sample_data/'+fname).values\n",
        "    # if 'test' in mode:\n",
        "    #   maskIdx = [3,7]\n",
        "    # else:\n",
        "    #   maskIdx = [0,1,2,4,5,6,8,9]\n",
        "    \n",
        "    self.xData = dataset[:,1:]/255\n",
        "    self.yData = dataset[:,0]\n",
        "    \n",
        "    # mask = np.isin(self.yData,maskIdx)\n",
        "\n",
        "    # self.xData = self.xData[mask]\n",
        "    # self.yData = self.yData[mask]\n",
        "    self.xData = self.xData[:128]\n",
        "    self.yData = self.yData[:128]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.xData)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return np.reshape(self.xData[idx],[1,28,28]),self.yData[idx]#to_categorical(self.yData[idx],num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLpXFPj3U6_A",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcS6A6WTYzYh",
        "colab_type": "text"
      },
      "source": [
        "#### Plot Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aaDoJI3Y2g8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_img(imgs,idx=42, title='Number'):\n",
        "  plt.figure(figsize=[7,7])\n",
        "  plt.imshow(imgs[idx],cmap='gray')\n",
        "  plt.axis('off')\n",
        "  plt.title(title)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74P3PLSZXUPl",
        "colab_type": "text"
      },
      "source": [
        "#### Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_DmOMbmU5L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mse_loss = nn.MSELoss(reduction='none')\n",
        "\n",
        "def margin_loss(x, labels, lamda=0.5, m_plus=0.9, m_minus=0.1):\n",
        "  v_c = torch.norm(x, dim=2, keepdim=True)\n",
        "  tmp1 = F.relu(m_plus - v_c).view(x.shape[0], -1) ** 2\n",
        "  tmp2 = F.relu(v_c - m_minus).view(x.shape[0], -1) ** 2\n",
        "  loss_ = labels*tmp1 + lamda*(1-labels)*tmp2\n",
        "  loss_ = loss_.sum(dim=1)\n",
        "  return loss_\n",
        "    \n",
        "def reconst_loss(recnstrcted, data):\n",
        "  loss = mse_loss(recnstrcted.view(recnstrcted.shape[0], -1), data.view(recnstrcted.shape[0], -1))\n",
        "  return 0.4 * loss.sum(dim=1)\n",
        "    \n",
        "def loss(x, recnstrcted, data, labels, lamda=0.5, m_plus=0.9, m_minus=0.1):\n",
        "  # print(type(recnstrcted))\n",
        "  loss_ = margin_loss(x, labels, lamda, m_plus, m_minus) + reconst_loss(recnstrcted, data)\n",
        "  return loss_.mean()\n",
        "\n",
        "def accuracy(indices, labels):\n",
        "  correct = 0.0\n",
        "  for i in range(indices.shape[0]):\n",
        "      if float(indices[i]) == labels[i]:\n",
        "          correct += 1\n",
        "  return correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xFXwqqtXmqM",
        "colab_type": "text"
      },
      "source": [
        "#### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDoeZQZcVHyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DeepCaps().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ksq5EcNFXs4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_epochs = 100\n",
        "lamda = 0.5\n",
        "m_plus = 0.9\n",
        "m_minus = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRG4fS2SX6O4",
        "colab_type": "code",
        "outputId": "e7d91026-f5ef-4ea7-e964-c3e76d88cda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "# train_data = MNISTData('train')\n",
        "# test_data = MNISTData('test')\n",
        "# train_loader = DataLoader(train_data,batch_size,True)\n",
        "# test_loader = DataLoader(test_data,batch_size,True)\n",
        "\n",
        "# MNIST\n",
        "# train_loader = torch.utils.data.DataLoader(\n",
        "#         datasets.MNIST('../data', train=True, download=True,\n",
        "#                        transform=transforms.Compose([\n",
        "#                            transforms.Pad(2), transforms.RandomCrop(28),\n",
        "#                            transforms.ToTensor()\n",
        "#                        ])),\n",
        "#         batch_size=batch_size, shuffle=True)\n",
        "# test_loader = torch.utils.data.DataLoader(\n",
        "#         datasets.MNIST('../data', train=False, download=True,\n",
        "#                        transform=transforms.Compose([\n",
        "#                            transforms.Pad(2), transforms.RandomCrop(28),\n",
        "#                            transforms.ToTensor()\n",
        "#                        ])),\n",
        "#         batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# FASHION-MNIST\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Pad(2), transforms.RandomCrop(28),\n",
        "                           transforms.ToTensor()\n",
        "                       ])),\n",
        "        batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST('../data', train=False, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Pad(2), transforms.RandomCrop(28),\n",
        "                           transforms.ToTensor()\n",
        "                       ])),\n",
        "        batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/26421880 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:00, 76096183.18it/s]                              \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../data/FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 443357.18it/s]\n",
            "  5%|▍         | 212992/4422102 [00:00<00:02, 1861086.58it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:00, 23152133.52it/s]                           \n",
            "8192it [00:00, 161233.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../data/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BwjqTULZ8DO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_loader, model, num_epochs, lr=0.001, batch_size=64, lamda=0.5, m_plus=0.9,  m_minus=0.1):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
        "    lambda1 = lambda epoch: 0.5**(epoch // 10)\n",
        "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "      loss_track=0.\n",
        "      for batch_idx, (data, label_) in enumerate(train_loader):\n",
        "        data = data.float().to(device)\n",
        "        labels = one_hot(label_.to(device))\n",
        "        optimizer.zero_grad()\n",
        "        outputs, masked, recnstrcted, indices = model(data, labels)\n",
        "        loss_val = loss(outputs, recnstrcted, data, labels, lamda, m_plus, m_minus)\n",
        "        loss_track += loss_val.item()\n",
        "        # print(recnstrcted.shape)\n",
        "        # plot_img(recnstrcted.squeeze().cpu().detach().numpy())\n",
        "        loss_val.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      print(f'EP {epoch}, Loss: {loss_track}, Accuracy: {accuracy(indices, label_.cpu())/indices.shape[0]}')\n",
        "      loss_track=0.\n",
        "      lr_scheduler.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68NfWHk8aQIm",
        "colab_type": "code",
        "outputId": "c505fe57-5226-4e30-f2ad-d0973ba47c58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        }
      },
      "source": [
        "train(train_loader,model,30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/30 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  3%|▎         | 1/30 [01:46<51:36, 106.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EP 0, Loss: 59756.566802978516, Accuracy: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  7%|▋         | 2/30 [03:32<49:43, 106.55s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EP 1, Loss: 59699.96783065796, Accuracy: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 3/30 [05:18<47:52, 106.38s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EP 2, Loss: 59672.4952545166, Accuracy: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-f27f641991df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-f6e9c4ecb970>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, num_epochs, lr, batch_size, lamda, m_plus, m_minus)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecnstrcted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecnstrcted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm_minus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss_track\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-9fb545319e0e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m#Block 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvcaps4_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mx_skip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvcaps3d4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvcaps3_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvcaps3_4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-7191e830484d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh_j\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_j\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnc_j\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnc_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-7191e830484d>\u001b[0m in \u001b[0;36mupdate_routing\u001b[0;34m(self, x, num_r)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mix\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_r\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0magreements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms_hat\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magreements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lFiT0Ycr4Kg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_,y_ = iter(train_loader).next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbEKxWmRyTcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p20ZZAHBsBzr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x_.float().to(device)\n",
        "y = one_hot(y_)\n",
        "\n",
        "outputs, masked, recnstrcted, indices = model(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljkkPm3qsWvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = torch.argmax(torch.norm(outputs,dim=-1),dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnYDeMxZ0N1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqJEi6HkxdNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH3Z3KkD_rq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_img(x_.squeeze(),3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc8KhJ__0QUh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_img(recnstrcted.squeeze().cpu().detach().numpy(),3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HgMLfMjZ4gS",
        "colab_type": "text"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJAlW_ZeZsZb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(model, test_loader, loss, batch_size, lamda=0.5, m_plus=0.9, m_minus=0.1):\n",
        "  test_loss = 0.0\n",
        "  correct = 0.0\n",
        "  for batch_idx, (data, label) in enumerate(test_loader):\n",
        "    data, labels = data.cuda(), one_hot(label.cuda())\n",
        "    outputs, masked_output, recnstrcted, indices = model(data)\n",
        "    \n",
        "    loss_test = model.loss(outputs, recnstrcted, data, labels, lamda, m_plus, m_minus)\n",
        "    test_loss += loss_test.data\n",
        "    indices_cpu, labels_cpu = indices.cpu(), label.cpu()\n",
        "\n",
        "    correct += accuracy(indices_cpu, labels_cpu)\n",
        "\n",
        "  print(\"\\nTest Loss: \", test_loss/len(test_loader.dataset), \"; Test Accuracy: \" , correct/len(test_loader.dataset) * 100,'\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpsLIaxaZ3tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " test(model, test_loader, loss, batch_size, lamda, m_plus, m_minus)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}