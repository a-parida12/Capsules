{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "capsnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iaqoe2hqTQSh",
        "colab_type": "text"
      },
      "source": [
        "Based on CapsNet implementation by [XifengGuo](https://github.com/XifengGuo/CapsNet-Pytorch)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHoNHSMUqZBS",
        "colab_type": "code",
        "outputId": "dcaa1be7-a12a-4821-854b-54e3404d445b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from keras.utils import to_categorical\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "import math\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOBgkXuBqeG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn0Kj4zoqf6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNISTData(Dataset):\n",
        "  def __init__(self,mode='train'):\n",
        "    super().__init__()\n",
        "    if 'test' in mode.lower():\n",
        "      fname = 'mnist_test.csv'\n",
        "    else:\n",
        "      fname = 'mnist_train_small.csv'\n",
        "      \n",
        "    dataset = pd.read_csv('sample_data/'+fname).values\n",
        "    if 'test' in mode:\n",
        "      maskIdx = [3,7]\n",
        "    else:\n",
        "      maskIdx = [0,1,2,4,5,6,8,9]\n",
        "    \n",
        "    self.xData = dataset[:,1:]/255\n",
        "    self.yData = dataset[:,0]\n",
        "    \n",
        "    mask = np.isin(self.yData,maskIdx)\n",
        "\n",
        "    self.xData = self.xData[mask]\n",
        "    self.yData = self.yData[mask]\n",
        "    # self.xData = self.xData[:128]\n",
        "    # self.yData = self.yData[:128]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.xData)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    return np.reshape(self.xData[idx],[1,28,28]),self.yData[idx]#to_categorical(self.yData[idx],num_classes=10)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vbbOhp-qmW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def squash(x):\n",
        "  norm = x.pow(2).sum(dim=2)\n",
        "  lengths = norm.sqrt()\n",
        "  x = x * (norm / (1+norm) / lengths).view(x.size(0),x.size(1),1)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhRSqM81ziSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Routing(nn.Module):\n",
        "  def __init__(self, inputCaps,outputCaps, nIters):\n",
        "    super().__init__()\n",
        "    self.nIters = nIters\n",
        "    self.b = nn.Parameter(torch.zeros((inputCaps,outputCaps)))\n",
        "\n",
        "  def forward(self, uPredict):\n",
        "    batchSize, inputCaps, outputCaps, outputDim = uPredict.size()\n",
        "\n",
        "    c = F.softmax(self.b)\n",
        "    s = (c.unsqueeze(2) * uPredict).sum(dim=1)\n",
        "    v = squash(s)\n",
        "\n",
        "    if self.nIters > 0:\n",
        "      bBatch = self.b.expand((batchSize,inputCaps,outputCaps))\n",
        "      for r in range(self.nIters):\n",
        "        v = v.unsqueeze(1)\n",
        "        bBatch = bBatch + (uPredict * v).sum(-1)\n",
        "\n",
        "        c = F.softmax(bBatch.view(-1,outputCaps)).view(-1,inputCaps,outputCaps,1)\n",
        "        s = (c * uPredict).sum(dim=1)\n",
        "        v = squash(s)\n",
        "      \n",
        "    return v\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klg6uX8R6z36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DenseCaps(nn.Module):\n",
        "  def __init__(self, inputCaps, inputDim, outputCaps, outputDim, routingModule):\n",
        "    super().__init__()\n",
        "    self.inpuptDim = inputDim\n",
        "    self.inputCaps = inputCaps\n",
        "    self.outputDim = outputDim\n",
        "    self.outputCaps = outputCaps\n",
        "    self.weights = nn.Parameter(torch.Tensor(inputCaps, inputDim, outputCaps * outputDim))\n",
        "    self.routingModule = routingModule\n",
        "    self.reset_params()\n",
        "\n",
        "  def reset_params(self):\n",
        "    stdv = 1/math.sqrt(self.inputCaps)\n",
        "    self.weights.data.uniform_(-stdv, stdv)\n",
        "  \n",
        "  def forward(self,  capsOutput):\n",
        "    capsOutput = capsOutput.unsqueeze(2)\n",
        "    uPredict = capsOutput.matmul(self.weights)\n",
        "    # import pdb; pdb.set_trace()\n",
        "    uPredict = uPredict.view(uPredict.size(0),self.inputCaps, self.outputCaps, self.outputDim)\n",
        "    v = self.routingModule(uPredict)\n",
        "    return v\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ3FRkgb8dqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PrimaryCaps(nn.Module):\n",
        "  def __init__(self, inputChannels, outputCaps, outputDim, kernelSize, stride):\n",
        "    super().__init__()\n",
        "    self.conv = nn.Conv2d(inputChannels, outputCaps * outputDim, kernel_size=kernelSize, stride = stride)\n",
        "    self.inputChannels = inputChannels\n",
        "    self.outputCaps = outputCaps\n",
        "    self.outputDim = outputDim\n",
        "\n",
        "  def forward(self, input):\n",
        "    out = self.conv(input)\n",
        "    N,C,H,W = out.size()\n",
        "    out = out.view(N,self.outputCaps, self.outputDim, H, W)\n",
        "\n",
        "    #N x OUTCAPS x OUTDIM\n",
        "    out = out.permute(0,1,3,4,2).contiguous()\n",
        "    out = out.view(out.size(0),-1,out.size(4))\n",
        "    out = squash(out)\n",
        "\n",
        "    return out\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXr4qE5nBv0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReconNet(nn.Module):\n",
        "  def __init__(self, nDim=16, nClasses=10):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(nDim * nClasses, 512)\n",
        "    self.fc2 = nn.Linear(512,1024)\n",
        "    self.fc3 = nn.Linear(1024,784)\n",
        "    self.nDim = nDim\n",
        "    self.nClasses = nClasses\n",
        "\n",
        "  def forward(self, x, target):\n",
        "    mask = Variable(torch.zeros((x.size()[0],self.nClasses)),requires_grad=False).to(device)\n",
        "    # mask = mask.float()\n",
        "    # import pdb; pdb.set_trace()\n",
        "    mask.scatter_(1,target.view(-1,1).long(),1.)\n",
        "    mask = mask.unsqueeze(2)\n",
        "    x = x*mask\n",
        "    x = x.view(-1,self.nDim * self.nClasses)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.sigmoid(self.fc3(x))\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xYWmmGGNzgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsNet(nn.Module):\n",
        "  def __init__(self, routingIters, nClasses=10):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(1,256,kernel_size=9,stride=1)\n",
        "    self.primarycaps = PrimaryCaps(256,32,8,9,2) #686 output\n",
        "    self.numPrimaryCaps = 32*6*6\n",
        "    routingModule = Routing(self.numPrimaryCaps,nClasses,routingIters)\n",
        "    self.digitCaps = DenseCaps(self.numPrimaryCaps,8,nClasses,16,routingModule=routingModule)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x = self.conv1(input)\n",
        "    x = F.relu(x)\n",
        "    x = self.primarycaps(x)\n",
        "    # print(x.shape)\n",
        "    x = self.digitCaps(x)\n",
        "    probs = x.pow(2).sum(dim=2).sqrt()\n",
        "\n",
        "    return x,probs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wixpJ0EqQ8lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CapsNetRecon(nn.Module):\n",
        "  def __init__(self,capsnet, reconNet, nClasses=10):\n",
        "    super().__init__()\n",
        "    self.capsnet = capsnet\n",
        "    self.reconNet = reconNet\n",
        "    self.nClasses=nClasses\n",
        "\n",
        "  def forward(self,x, target):\n",
        "    x, probs = self.capsnet(x)\n",
        "    \n",
        "    recon = self.reconNet(x,target)\n",
        "    return recon, probs, x\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-XBWZHGRZ-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MarginLoss(nn.Module):\n",
        "  def __init__(self, mPos, mNeg,lambda_):\n",
        "    super().__init__()\n",
        "    self.mPos = mPos\n",
        "    self.mNeg = mNeg\n",
        "    self.lambda_ =lambda_\n",
        "\n",
        "  def forward(self, lengths, targets, avg=True):\n",
        "    t = torch.zeros(lengths.size())\n",
        "    t = t.to(device)\n",
        "\n",
        "    t = t.scatter_(1, targets.data.view(-1,1).long(), 1.)\n",
        "    targets = Variable(t)\n",
        "    losses = targets.float() * F.relu(self.mPos - lengths).pow(2) + self.lambda_ * (1-targets.float()) * F.relu(lengths - self.mNeg).pow(2)\n",
        "\n",
        "    return losses.mean() if avg else losses.sum()\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntRF6EAJUUhb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Trainer:\n",
        "  \n",
        "  def __init__(self,batchSize=128, lr=1e-3, epochs=100, routings=3):\n",
        "    \n",
        "    self.epochs=epochs\n",
        "    \n",
        "    # self.trDataset = MNISTData()\n",
        "    # self.trLoader = DataLoader(self.trDataset,num_workers=1,batch_size=batchSize,shuffle=True)\n",
        "    self.trLoader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=True, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Pad(2), transforms.RandomCrop(28),\n",
        "                           transforms.ToTensor()\n",
        "                       ])),\n",
        "        batch_size=batchSize, shuffle=True)\n",
        "    # tsDataset = MNISTData(mode='test')\n",
        "    # self.tstLoader = DataLoader(tsDataset,num_workers=1,batch_size=batchSize,shuffle=True)\n",
        "    self.tstLoader = torch.utils.data.DataLoader(\n",
        "        datasets.MNIST('../data', train=False, download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.Pad(2), transforms.RandomCrop(28),\n",
        "                           transforms.ToTensor()\n",
        "                       ])),\n",
        "        batch_size=batchSize, shuffle=True)\n",
        "    capsnet = CapsNet(3)\n",
        "    reconNet = ReconNet()\n",
        "    self.model = CapsNetRecon(capsnet,reconNet)\n",
        "    self.model.to(device)\n",
        "    \n",
        "    self.optim = torch.optim.Adam(self.model.parameters(),lr)\n",
        "    self.lossfn = MarginLoss(0.9,0.1,0.5)\n",
        "\n",
        "\n",
        "  def _trainEpoch(self):\n",
        "    trLoss = []\n",
        "    for x,y in self.trLoader:\n",
        "\n",
        "      self.optim.zero_grad()\n",
        "\n",
        "      x = x.float().to(device)\n",
        "      y = y.float().to(device)\n",
        "      recon, yPred,_ = self.model(x,y)\n",
        "      \n",
        "      loss = self.lossfn(yPred,y)\n",
        "      reconLoss = F.mse_loss(recon,x.view(-1,784))\n",
        "      loss = loss + (5e-2)*reconLoss\n",
        "\n",
        "\n",
        "      loss.backward()\n",
        "      self.optim.step()\n",
        "      \n",
        "      trLoss += [loss.item()]\n",
        "      \n",
        "    return np.sum(trLoss)\n",
        "  \n",
        "  def train(self):\n",
        "    epLoss = []\n",
        "    self.model.train()\n",
        "    for ep in tqdm(range(self.epochs)):\n",
        "      epLoss += [self._trainEpoch()]\n",
        "      print(f'\\n---EPOCH {ep}---')\n",
        "      print(f'Train Loss: {epLoss[-1]:.6f}')\n",
        "    return epLoss\n",
        "    \n",
        "  def evalModel(self):\n",
        "    self.model.eval()\n",
        "    correct = 0\n",
        "    for x,y in tqdm(self.tstLoader):\n",
        "      x = x.float().to(device)\n",
        "      y = y.float().to(device)\n",
        "      \n",
        "      yPred, recon = self.model(x)\n",
        "      \n",
        "      yPred = yPred.data.max(1)[1]\n",
        "      yTrue = y.data.max(1)[1]\n",
        "      correct += yPred.eq(yTrue).cpu().sum()\n",
        "    acc = correct / len(self.tstLoader.dataset)\n",
        "    print(f'EVALUATION ACCURACY: {acc*100:.4f}%')  \n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ui_Wr5EdS4Q",
        "colab_type": "code",
        "outputId": "1d9368c4-81c8-4ea5-c058-132a3b85f42b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "train = Trainer(epochs=15)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 27621780.28it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 457532.00it/s]\n",
            "  1%|          | 16384/1648877 [00:00<00:11, 142039.32it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 7459778.20it/s]                            \n",
            "8192it [00:00, 176583.21it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ-lFVNUdUtT",
        "colab_type": "code",
        "outputId": "84f8bf56-9c62-495f-d765-5c3affb583a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 888
        }
      },
      "source": [
        "train.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/15 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "  7%|▋         | 1/15 [03:02<42:29, 182.11s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---EPOCH 0---\n",
            "Train Loss: 6.364009\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 13%|█▎        | 2/15 [06:03<39:26, 182.02s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---EPOCH 1---\n",
            "Train Loss: 2.230927\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 3/15 [09:05<36:23, 181.94s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---EPOCH 2---\n",
            "Train Loss: 1.707877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 27%|██▋       | 4/15 [12:07<33:20, 181.86s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---EPOCH 3---\n",
            "Train Loss: 1.466799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 33%|███▎      | 5/15 [15:09<30:18, 181.82s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---EPOCH 4---\n",
            "Train Loss: 1.315153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 6/15 [18:10<27:15, 181.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---EPOCH 5---\n",
            "Train Loss: 1.216962\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 47%|████▋     | 7/15 [21:12<24:13, 181.72s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "---EPOCH 6---\n",
            "Train Loss: 1.138959\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENCODERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'raw'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7596ba849953>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-74b24f42d821>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m       \u001b[0mepLoss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n---EPOCH {ep}---'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Train Loss: {epLoss[-1]:.6f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-74b24f42d821>\u001b[0m in \u001b[0;36m_trainEpoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_trainEpoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtrLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrLoader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \"\"\"\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m255\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteStorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m     \u001b[0;31m# PIL image mode: L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'YCbCr'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mtobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         \u001b[0;31m# unpack data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m         \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m_getencoder\u001b[0;34m(mode, encoder_name, args, extra)\u001b[0m\n\u001b[1;32m    447\u001b[0m         \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENCODERS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_NG-qL2dpOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = train.model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Btoig9WZrKW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model,'./capsNet.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9BXR5xHssUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_=model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6XALy5BmAKjX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,y = iter(train.trLoader).next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNuDSDW5AtVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(x[4,0],cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBBLtjZFAwPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = x.float().to(device)\n",
        "y = y.float().to(device)\n",
        "recon, yp, dc = model(x,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voctbPocA-uX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recon = recon.view(-1,28,28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJpNvW8oBE1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recon = recon.cpu().detach().numpy()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99W7qi8wUs44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(recon[4],cmap='gray')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz6IhtsUUvII",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yp[4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLl2S8fsUzFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.argmax(yp[4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d03rvzP3aGii",
        "colab_type": "text"
      },
      "source": [
        "## Visualisations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJmulPWZPzPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import ToTensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWgY607UaKys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = MNIST('../data', train=False, transform=ToTensor())\n",
        "# model.to(torch.device('cpu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvS8zbm1aRox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# (1x28x28 tensor input)\n",
        "def get_digit_caps(model, image):\n",
        "    input_ = Variable(image.unsqueeze(0), volatile=True).to(device)\n",
        "    digit_caps, probs= model.capsnet(input_)\n",
        "    return digit_caps\n",
        "\n",
        "# takes digit_caps output and target label\n",
        "def get_reconstruction(model, digit_caps, label):\n",
        "    target = Variable(torch.LongTensor([label]), volatile=True).to(device)\n",
        "    reconstruction = model.reconNet(digit_caps, target)\n",
        "    return reconstruction.data.cpu().numpy()[0].reshape(28, 28)\n",
        "\n",
        "# create reconstructions with perturbed digit capsule\n",
        "def dimension_perturbation_reconstructions(model, digit_caps, label, dimension, dim_values):\n",
        "    reconstructions = []\n",
        "    for dim_value in dim_values:\n",
        "        digit_caps_perturbed = digit_caps.clone()\n",
        "        digit_caps_perturbed[0, label, dimension] = dim_value\n",
        "        reconstruction = get_reconstruction(model, digit_caps_perturbed, label)\n",
        "        reconstructions.append(reconstruction)\n",
        "    return reconstructions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8L_us5Ncas5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get reconstructions\n",
        "images = []\n",
        "reconstructions = []\n",
        "for i in range(8):\n",
        "    image_tensor, label = dataset[i]\n",
        "    digit_caps = get_digit_caps(model.float().to(device), image_tensor.float().to(device))\n",
        "    reconstruction = get_reconstruction(model, digit_caps, label)\n",
        "    images.append(image_tensor.numpy()[0])\n",
        "    reconstructions.append(reconstruction)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6J4_mfhawec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot reconstructions\n",
        "fig, axs = plt.subplots(2, 8, figsize=(16, 4))\n",
        "axs[0, 0].set_ylabel('Org image', size='large')\n",
        "axs[1, 0].set_ylabel('Reconstruction', size='large')\n",
        "for i in range(8):\n",
        "    axs[0, i].imshow(images[i], cmap='gray')\n",
        "    axs[1, i].imshow(reconstructions[i], cmap='gray')\n",
        "    axs[0, i].set_yticks([])\n",
        "    axs[0, i].set_xticks([])\n",
        "    axs[1, i].set_yticks([])\n",
        "    axs[1, i].set_xticks([])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxP_Bl9Na1G8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "digit, label = dataset[420]\n",
        "perturbed_reconstructions = []\n",
        "perturbation_values = [0.05*i for i in range(-5, 6)]\n",
        "digit_caps = get_digit_caps(model, digit)\n",
        "for dimension in range(16):\n",
        "    perturbed_reconstructions.append(\n",
        "        dimension_perturbation_reconstructions(model, digit_caps, label,\n",
        "                                               dimension, perturbation_values)\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFdWgpdPa9kW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axs = plt.subplots(16, 11, figsize=(11*1.5, 16*1.5))\n",
        "for i in range(16):\n",
        "    axs[i, 0].set_ylabel('dim {}'.format(i), size='large')\n",
        "    for j in range(11):\n",
        "        axs[i, j].imshow(perturbed_reconstructions[i][j], cmap='gray')\n",
        "        axs[i, j].set_yticks([])\n",
        "        axs[i, j].set_xticks([])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUwzrrsld_3Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}